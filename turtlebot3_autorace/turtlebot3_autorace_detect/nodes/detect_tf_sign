#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""Inception v3 architecture 모델을 retraining한 모델을 이용해서 이미지에 대한 추론(inference)을 진행하는 예제"""

import time
import numpy as np
import tensorflow as tf
import os
import cv2
import math
import rospy
from enum import Enum
from std_msgs.msg import UInt8
from sensor_msgs.msg import Image, CompressedImage
from cv_bridge import CvBridge, CvBridgeError


class DetectSign():
    def __init__(self):

        rospy.loginfo('Start detect sign')

        self.modelFullPath = '/home/devel/catkin_ws/src/turtlebot3_autorace/turtlebot3_autorace_detect/nodes/tf_model/output_graph.pb'
        self.labelsFullPath = '/home/devel/catkin_ws/src/turtlebot3_autorace/turtlebot3_autorace_detect/nodes/tf_model/output_labels.txt'

        self.sub_image_type = "raw" # you can choose image type "compressed", "raw"
        self.pub_image_type = "compressed" # you can choose image type "compressed", "raw"

        self.sub_image = rospy.Subscriber('/camera/image', Image, self.cbFindTrafficSign, queue_size=1)
        self.TrafficSign = Enum('TrafficSign', 'divide stop parking tunnel three_way go_to_left go_to_right etc obstacle')

        self.i = 0
        self.pic_num = 0
        self.last_pic = 0

        self.new_img = None
	
	if self.sub_image_type == "compressed" :
	   self.sub_image_original = rospy.Subscriber('detect/image_input/compressed', CompressedImage, self.cbFindTrafficSign, queue_size = 1)
	elif self.sub_image_type == "raw" :
	   self.sub_image_original = rospy.Subscriber('detect/image_input',Image, self.cbFindTrafficSign, queue_size = 1)

	self.pub_traffic_sign = rospy.Publisher('detect/traffic_sign', UInt8, queue_size =1)
	
	if self.pub_image_type == "compressed" :
	   self.pub_image_traffic_sign = rospy.Publisher('/detect/image_output/compressed', CompressedImage, queue_size = 1)
 
	elif self.pub_image_type == "raw" :
	   self.pub_image_traffic_sign = rospy.Publisher('/detect/image_output', Image, queue_size = 1)

        self.cvBridge = CvBridge()
        self.counter = 1
       # self.pub_traffic_sign = rospy.Publisher('/test', UInt8, queue_size=1 )

#    def cbFindTrafficSign(self, image_msg):
#	if self.sub_image_type == "compressed":
#	   np_arr = np.fromstring(image_msg.data, np.uint8)
#	   cv_image_input = cv2.Imdecode(np_arr, cv2.IMREAD_COLOR)
#	elif self.sub_image_type == "raw" :
#	   cv_image_input = self.cvBridge.imgmsg_to_cv2(image_msg,"rgba8")
#        self.run_camera(image_msg)
	#self.pub_traffic_sign.publish(self.new_img)
       # self.run_inference_on_image()

    def angle(self,pt1,pt2,pt0):
        dx1 = pt1[0][0] - pt0[0][0]
        dy1 = pt1[0][1] - pt0[0][1]
        dx2 = pt2[0][0] - pt0[0][0]
        dy2 = pt2[0][1] - pt0[0][1]
        return float((dx1*dx2 + dy1*dy2))/math.sqrt(float((dx1*dx1 + dy1*dy1))*(dx2*dx2 + dy2*dy2) + 1e-10)


    def create_graph(self):
        """저장된(saved) GraphDef 파일로부터 graph를 생성하고 saver를 반환한다."""
        # 저장된(saved) graph_def.pb로부터 graph를 생성한다.
        with tf.gfile.FastGFile(self.modelFullPath, 'rb') as f:
            graph_def = tf.GraphDef()
            graph_def.ParseFromString(f.read())
            _ = tf.import_graph_def(graph_def, name='')

   # def run_camera(self, data):
    def cbFindTrafficSign(self, data):
        if self.counter % 3 != 0:
            self.counter += 1
            return
        else:
            self.counter = 1


        if self.sub_image_type == "compressed":
           np_arr = np.fromstring(image_msg.data, np.uint8)
           cv_image_input = cv2.Imdecode(np_arr, cv2.IMREAD_COLOR)
        elif self.sub_image_type == "raw" :
           cv_image_input = self.cvBridge.imgmsg_to_cv2(data,"bgr8") #rgba8

        contours = {}
        approx = []
        scale = 2
        frame = self.cvBridge.imgmsg_to_cv2(data, "bgr8")
	#print("1")
	#print(type(data))
	#print("2")
	#print(type(frame))
	#cv2.imshow('frame',data), cv2.waitKey(1) & 0xF
	kernel = np.ones((1,1),np.uint8)
        #ret, frame = self.cvBridge.imgmsg_to_cv2(data, "bgr8")
	#cv2.imshow('frame',frame), cv2.waitKey(1) & 0xF
	flag = True
	while(flag):
            flag = False
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            canny = cv2.Canny(frame,100,240,3)
	    #dilation = cv2.dilate(canny, kernel, iterations = 4)
            #erosion = cv2.erode(canny, kernel, iterations = 1)
            canny2, contours, hierarchy = cv2.findContours(canny,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
            for i in range(0,len(contours)):
                #approximate the contour with accuracy proportional to
                #the contour perimeter
                approx = cv2.approxPolyDP(contours[i],cv2.arcLength(contours[i],True)*0.02,True)

                #Skip small or non-convex objects
                if(abs(cv2.contourArea(contours[i]))<100 or not(cv2.isContourConvex(approx))):
                    continue

                #triangle
                if(len(approx) == 3):
                    print('READ_TRIANGLE')
                    x,y,w,h = cv2.boundingRect(contours[i])
                    cv2.drawContours(frame, [approx], -1, (0, 255, 0), 2)
                    for j in range(3):
                        a = cv2.circle(frame, (approx[j][0][0], approx[j][0][1]), 2, (0, 255,0), thickness=3, lineType=8, shift=0)
                    
                    if w>50 and h>50 :
                          self.new_img= frame[y:y+h,x:x+w]
		 	  #self.pub_traffic_sign.publish(frame)
			  print('-------------------------------------')
			  print("BEFORE_CALCULATING")
			  self.run_inference_on_image(self.new_img)
			  print("AFTER_CALCULATING")
			  print('-------------------------------------')
			  #time.sleep(2)
			  #return self.new_img

                elif(len(approx)>=4 and len(approx)<=6):
                    #nb vertices of a polygonal curve
                    vtc = len(approx)
                    #get cos of all corners
                    cos = []
                    for j in range(2,vtc+1):
                        cos.append(self.angle(approx[j%vtc],approx[j-2],approx[j-1]))
                    #sort ascending cos
                    cos.sort()
                    #get lowest and highest
                    mincos = cos[0]
                    maxcos = cos[-1]

                    #Use the degrees obtained above and the number of vertices
                    #to determine the shape of the contour
                    x,y,w,h = cv2.boundingRect(contours[i])
                    if(vtc==4):
			print("READ_RECT")
                        cv2.drawContours(frame, [approx], -1, (0, 255, 0), 3)
                        for j in range(3):
                           a = cv2.circle(frame, (approx[j][0][0], approx[j][0][1]), 2, (0, 255,0), thickness=3, lineType=8, shift=0)

                        if w>150 and h>150 :
                              self.new_img= frame[y:y+h,x:x+w]
			      #self.pub_traffic_sign.publish(frame)
			      print('-------------------------------------')
			      print("BEFORE_CALCULATING")
			      self.run_inference_on_image(self.new_img)
			      print("AFTER_CALCULATING")
			      print('-------------------------------------')
			      #cv2.imshow('frame',frame)
			      #time.sleep(2)
			      #return self.new_img
                    else:
			print("READ_CIRC")
                        #detect and label circle
                        area = cv2.contourArea(contours[i])
                        x,y,w,h = cv2.boundingRect(contours[i])
                        radius = w/2
                        if(abs(1 - (float(w)/h))<=2 and abs(1-(area/(math.pi*radius*radius)))<=0.2):
                            cv2.drawContours(frame, [approx], -1, (0, 255, 0), 3)
                            for j in range(3):
                               a = cv2.circle(frame, (approx[j][0][0], approx[j][0][1]), 2, (0, 255,0), thickness=3, lineType=8, shift=0)
                            if w>50 and h>50 :
                               self.new_img= frame[y:y+h,x:x+w]
			       #self.pub_traffic_sign.publish(frame)
			       print('-------------------------------------')
			       print("BEFORE_CALCULATING")
			       self.run_inference_on_image(self.new_img)
			       print("AFTER_CALCULATING")
			       print('-------------------------------------')
			       #return self.new_img
			       #print(type(self.new_img))

	    #print(type(frame))
	    #print(type(self.new_img))
	    #if(hasattr(frame, 'dtype')):
	   # 	self.run_inference_on_image(frame)
        #cv2.imshow('frame',frame), cv2.waitKey(1) & 0xFF
           # 	cv2.imshow('canny',canny)
           # if self.pic_num != 0 :
           #         break

        #When everything done, release the capture
        #cv2.destroyAllWindows()
        if self.pub_image_type == "compressed":
                # publishes traffic sign image in compressed type
                self.pub_image_traffic_sign.publish(self.cvBridge.cv2_to_compressed_imgmsg(canny, "jpg"))
#cv_image_input
        elif self.pub_image_type == "raw":
                # publishes traffic sign image in raw type
                self.pub_image_traffic_sign.publish(self.cvBridge.cv2_to_imgmsg(canny, "bgr8"))




    def run_inference_on_image(self, frame):
        answer = None
        #self.i = 0
        #for file_type in ['tf_test'] :

         #for img in os.listdir(file_type):

          #imagePath =  'tf_test/'+str(self.i)+'.jpg'
          #if not tf.gfile.Exists(imagePath):
          #    tf.logging.fatal('File does not exist %s', imagePath)
          #    return answer

          #image_data = tf.gfile.FastGFile(imagePath, 'rb').read()
        image_data = np.array(frame)[:,:,0:3]

          # 저장된(saved) GraphDef 파일로부터 graph를 생성한다.
        self.create_graph()

        with tf.Session() as sess:

            softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')
            predictions = sess.run(softmax_tensor,
                                   {'DecodeJpeg:0': image_data})
            predictions = np.squeeze(predictions)
            top_k = predictions.argsort()[-2:][::-1]  # 가장 높은 확률을 가진 5개(top 5)의 예측값(predictions)을 얻는다.
            f = open(self.labelsFullPath, 'rb')
            lines = f.readlines()
            labels = [str(w).replace("\n", "") for w in lines]
            print("---------------------------")
            for node_id in top_k:
                human_string = labels[node_id]
                score = predictions[node_id]
                print('%s (score = %.5f)' % (human_string, score))
            print('---------------------------')
            answer = labels[top_k[0]]
            #return answer
            self.i += 1

            print(type(answer))

            if answer == 'stop':
                result_sign = self.TrafficSign.stop.value
                self.pub_traffic_sign.publish(result_sign)

            elif answer == 'parking':
                  result_sign = result_sign = self.TrafficSign.parking.value
                  self.pub_traffic_sign.publish(result_sign)

            elif answer == 'tunnel':
                  result_sign = result_sign = self.TrafficSign.tunnel.value
                  self.pub_traffic_sign.publish(result_sign)

            elif answer == 'three_way':
                  result_sign = result_sign = self.TrafficSign.three_way.value
                  self.pub_traffic_sign.publish(result_sign)

            elif answer == 'go_to_left':
                  result_sign = result_sign = self.TrafficSign.go_to_left.value
                  self.pub_traffic_sign.publish(result_sign)

            elif answer == 'go_to_right':
                  result_sign = result_sign = self.TrafficSign.go_to_right.value
                  self.pub_traffic_sign.publish(result_sign)

            elif answer == 'obstacle':
                  result_sign = result_sign = self.TrafficSign.obstacle.value
                  self.pub_traffic_sign.publish(result_sign)

            else:
                pass


    def main(self):
        rospy.spin()   

if __name__ == '__main__':
    rospy.init_node('detect_tf_sign')
    node = DetectSign()
    node.main()

